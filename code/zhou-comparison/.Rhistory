GeoResults$KGlasso[ind] = GeoResults$KGlasso[ind] + GeoKGlassoError/(NumInstances*TrialsPerInstance)
}
}
}
output<- list(Results = results,OpResults = OpResults, GeoResults = GeoResults, Example=A[1:min(SmallDimension,10),1:min(SmallDimension,10)])
}
#doing the learning curves
res =LearningCurve(20,20,1,10,NumInstances = 3,TrialsPerInstance = 5)
LearningCurvePlot(res$Results)
#do the plots
#geodesic
lp=LearningCurvePlot(res$GeoResults)
lp = lp + ggtitle("Error in Geodesic distance") #cool way to title on the fly :)
pdf("20-50-lc-geo.pdf")
lp
dev.off()
lp
lp=LearningCurvePlot(res$OpResults)
lp = lp + ggtitle("Error in operator norm")
pdf("25-50-lc-op.pdf")
lp
dev.off()
lp
lp=LearningCurvePlot(res$Results)
lp = lp + ggtitle("Error in Frobenius norm")
pdf("25-50-lc-frob.pdf")
lp
dev.off()
lp
#doing the learning curves
res =LearningCurve(25,50,1,15,NumInstances = 3,TrialsPerInstance = 10)
#doing the learning curves
res =LearningCurve(25,50,1,15,NumInstances = 3,TrialsPerInstance = 10)
#doing the learning curves
res =LearningCurve(25,50,1,15,NumInstances = 3,TrialsPerInstance = 10)
#doing the learning curves
res =LearningCurve(50,50,1,15,NumInstances = 3,TrialsPerInstance = 10)
lp = LearningCurvePlot(res$Results)
#do the plots
#geodesic
lp=LearningCurvePlot(res$GeoResults)
lp = lp + ggtitle("Error in Geodesic distance") #cool way to title on the fly :)
pdf("25-50-lc-geo.pdf")
lp
dev.off()
lp
lp=LearningCurvePlot(res$OpResults)
lp = lp + ggtitle("Error in operator norm")
pdf("25-50-lc-op.pdf")
lp
dev.off()
lp
lp=LearningCurvePlot(res$Results)
lp = lp + ggtitle("Error in Frobenius norm")
pdf("25-50-lc-frob.pdf")
lp
dev.off()
lp
#this time let n to infinity. Question: what model? Sparse?
SparsityCurve <-function(SmallDimension,BigDimension,NumSamples, MinSparse,MaxSparse,NumInstances=2,TrialsPerInstance=2){
results = data.frame(Sparsity = c(MinSparse:MaxSparse),Gemini=0,RegSink = 0,Sink = 0, Trivial=0, KGlasso = 0)
#make copies for the other error metrics.
GeoResults = data.frame(results)
OpResults = data.frame(results)
setVariable(matlab, SmallDimension=SmallDimension, BigDimension=BigDimension,NumSamples=NumSamples)
for(j in MinSparse:MaxSparse){
for (l in 1:NumInstances){
#define sparse INVERSE covariance
invA = .5*diag(SmallDimension)
for (term in 1:SmallDimension*sparsity/10){
#print(term)
x=sample(1:SmallDimension,2,replace=F)
invA[x[1],x[1]]=invA[x[1],x[1]]+1
invA[x[1],x[2]]=invA[x[1],x[2]]-1
invA[x[2],x[1]]=invA[x[2],x[1]]-1
invA[x[2],x[2]]=invA[x[2],x[2]]+1
}
A = solve(invA)
rootA = sqrtm(A)
invA = invA/tr(invA)
normA = norm(invA,"F")^2
detinvA = DetNorm(invA)
#print(c("detA",det(invA)))
#actually the INVERSE should be sparse
invB = .5*diag(BigDimension)
for (term in 1:BigDimension*sparsity/10){
#print(term)
x=sample(1:BigDimension,2,replace=F)
invB[x[1],x[1]]=invB[x[1],x[1]]+1
invB[x[1],x[2]]=invB[x[1],x[2]]-1
invB[x[2],x[1]]=invB[x[2],x[1]]-1
invB[x[2],x[2]]=invB[x[2],x[2]]+1
}
B = solve(invB)
rootB = sqrtm(B)
invB = invB/tr(invB)
normB = norm(invB,"F")^2
detinvB = DetNorm(invB)
#for each covariance we will compute the estimate with fresh samples from the model a few times
for(k in 1:TrialsPerInstance){
#create the fresh samples
X = list(0*c(1:NumSamples))
dat = matrix(0, ncol = NumSamples, nrow = SmallDimension*BigDimension)
for(i in 1:NumSamples){
#create the data
X[[i]] = rootA%*%matrix(rnorm(SmallDimension*BigDimension,sd=1), nrow=SmallDimension, ncol=BigDimension)%*%rootB
dat[,i] = X[[i]]
}
#print(c("dat: ",dat, nrow(dat), ncol(dat)))
ind = j - MinSparse + 1
#trivial frobenius error
TrivialError = norm(invA - diag(SmallDimension)/SmallDimension,"F")^2 / normA
results$Trivial[ind] = results$Trivial[ind]+ TrivialError/(NumInstances*TrialsPerInstance)
#operator error
OpTrivialError = norm(invA - diag(SmallDimension)/SmallDimension,"I")^2
OpResults$Trivial[ind] = OpResults$Trivial[ind]+ OpTrivialError/(NumInstances*TrialsPerInstance)
#geodesic trivial
GeoTrivialError = GeodesicDistance(detinvA, diag(SmallDimension))
#GeoResults$Trivial[j] = GeoResults$Trivial[j] + GeoTrivialError/(NumInstances*TrialsPerInstance)
GeoResults$Trivial[ind] = GeoResults$Trivial[ind] + 1/(NumInstances*TrialsPerInstance)
#gemini
#set gemini penalties
GeminiRegFactor = 1*sqrt(log(SmallDimension)/BigDimension)
tic("geminiB")
out <- GeminiBmult(X, GeminiRegFactor, penalize.diagonal=FALSE)
toc()
GeminiEstimate = out$B.hat.inv
print(c("Gemini det",det(GeminiEstimate)))
#calculate frobenius error
GeminiError = norm(invA - (GeminiEstimate/tr(GeminiEstimate)),"F")^2 / normA
results$Gemini[ind] = results$Gemini[ind]+ GeminiError/(NumInstances*TrialsPerInstance)
#operator error
OpGeminiError = norm(invA - (GeminiEstimate/tr(GeminiEstimate)),"I")^2
OpResults$Gemini[ind] = OpResults$Gemini[ind]+ OpGeminiError/(NumInstances*TrialsPerInstance)
#calculate geodesic error
GeoGeminiError = GeodesicDistance(detinvA, DetNorm(GeminiEstimate))^2/GeoTrivialError^2
GeoResults$Gemini[ind] = GeoResults$Gemini[ind] + GeoGeminiError/(NumInstances*TrialsPerInstance)
######Sinkhorn
#regularized Sinkhorn
#set sinkhorn penalties
tic("sinkhorn")
SinkEstimate = sinkhorn(X,tol = .01)[[1]]
toc()
#print(c("Sinkhorn det",det(RegSinkEstimate)))
#calculate frobenius
SinkError = norm(invA - (SinkEstimate/tr(SinkEstimate)),"F")^2 / normA
results$Sink[ind] = results$Sink[ind]+ SinkError/(NumInstances*TrialsPerInstance)
#operator error
OpUnregSinkError = norm(invA - (SinkEstimate/tr(SinkEstimate)),"I")^2
OpResults$Sink[ind] = OpResults$Sink[ind]+ OpUnregSinkError/(NumInstances*TrialsPerInstance)
#geodesic distance
GeoUnregSinkError = GeodesicDistance(DetNorm(invA), DetNorm(SinkEstimate))^2/GeoTrivialError^2
GeoResults$Sink[ind] = GeoResults$Sink[ind] + GeoUnregSinkError/(NumInstances*TrialsPerInstance)
#regularized Sinkhorn
#set sinkhorn penalties
RegSinkFactor = 1
tic("regularized sinkhorn")
RegSinkEstimate = regsinkhorn(X,tol = .01, reg = RegSinkFactor)[[1]]
toc()
print(c("Sinkhorn det",det(RegSinkEstimate)))
#calculate frobenius
RegSinkError = norm(invA - (RegSinkEstimate/tr(RegSinkEstimate)),"F")^2 / normA
results$RegSink[ind] = results$RegSink[ind]+ RegSinkError/(NumInstances*TrialsPerInstance)
#operator error
OpSinkError = norm(invA - (RegSinkEstimate/tr(RegSinkEstimate)),"I")^2
OpResults$RegSink[ind] = OpResults$RegSink[ind]+ OpSinkError/(NumInstances*TrialsPerInstance)
#geodesic distance
GeoSinkError = GeodesicDistance(DetNorm(invA), DetNorm(RegSinkEstimate))^2/GeoTrivialError^2
GeoResults$RegSink[ind] = GeoResults$RegSink[ind] + GeoSinkError/(NumInstances*TrialsPerInstance)
#KGlasso
#print(c("MatReg, ", MatReg))
setVariable(matlab, dat = dat)
#evaluate(matlab, "SmallDimension, class(BigDimension),class(NumSamples)")
evaluate(matlab,"[C,D] = KGL_R(dat,SmallDimension,BigDimension,NumSamples,.4,.4,30,.01);")
KGlassoEstimate = getVariable(matlab,"C")$C
KGlassoError = norm(invA - (KGlassoEstimate/tr(KGlassoEstimate)),"F")^2 / normA
#print(c("Glasso Error: ",KGlassoError))
results$KGlasso[ind] = results$KGlasso[ind]+ KGlassoError/(NumInstances*TrialsPerInstance)
#operator error
OpKGlassoError = norm(invA - (KGlassoEstimate/tr(KGlassoEstimate)),"I")^2
OpResults$KGlasso[ind] = OpResults$KGlasso[ind]+ OpKGlassoError/(NumInstances*TrialsPerInstance)
#geodesic distance
GeoKGlassoError = GeodesicDistance(DetNorm(invA), DetNorm(KGlassoEstimate))^2/GeoTrivialError^2
GeoResults$KGlasso[ind] = GeoResults$KGlasso[ind] + GeoKGlassoError/(NumInstances*TrialsPerInstance)
}
}
}
output<- list(Results = results,OpResults = OpResults, GeoResults = GeoResults, Example=A[1:min(SmallDimension,10),1:min(SmallDimension,10)])
}
#doing the learning curves
res =LearningCurve(20,20,1,4,10)
#doing the learning curves
res =SparsityCurve(20,20,1,4,10)
#this time let n to infinity. Question: what model? Sparse?
SparsityCurve <-function(SmallDimension,BigDimension,NumSamples, MinSparse,MaxSparse,NumInstances=2,TrialsPerInstance=2){
results = data.frame(Sparsity = c(MinSparse:MaxSparse),Gemini=0,RegSink = 0,Sink = 0, Trivial=0, KGlasso = 0)
#make copies for the other error metrics.
GeoResults = data.frame(results)
OpResults = data.frame(results)
setVariable(matlab, SmallDimension=SmallDimension, BigDimension=BigDimension,NumSamples=NumSamples)
for(sparsity in MinSparse:MaxSparse){
for (l in 1:NumInstances){
#define sparse INVERSE covariance
invA = .5*diag(SmallDimension)
for (term in 1:SmallDimension*sparsity/10){
#print(term)
x=sample(1:SmallDimension,2,replace=F)
invA[x[1],x[1]]=invA[x[1],x[1]]+1
invA[x[1],x[2]]=invA[x[1],x[2]]-1
invA[x[2],x[1]]=invA[x[2],x[1]]-1
invA[x[2],x[2]]=invA[x[2],x[2]]+1
}
A = solve(invA)
rootA = sqrtm(A)
invA = invA/tr(invA)
normA = norm(invA,"F")^2
detinvA = DetNorm(invA)
#print(c("detA",det(invA)))
#actually the INVERSE should be sparse
invB = .5*diag(BigDimension)
for (term in 1:BigDimension*sparsity/10){
#print(term)
x=sample(1:BigDimension,2,replace=F)
invB[x[1],x[1]]=invB[x[1],x[1]]+1
invB[x[1],x[2]]=invB[x[1],x[2]]-1
invB[x[2],x[1]]=invB[x[2],x[1]]-1
invB[x[2],x[2]]=invB[x[2],x[2]]+1
}
B = solve(invB)
rootB = sqrtm(B)
invB = invB/tr(invB)
normB = norm(invB,"F")^2
detinvB = DetNorm(invB)
#for each covariance we will compute the estimate with fresh samples from the model a few times
for(k in 1:TrialsPerInstance){
#create the fresh samples
X = list(0*c(1:NumSamples))
dat = matrix(0, ncol = NumSamples, nrow = SmallDimension*BigDimension)
for(i in 1:NumSamples){
#create the data
X[[i]] = rootA%*%matrix(rnorm(SmallDimension*BigDimension,sd=1), nrow=SmallDimension, ncol=BigDimension)%*%rootB
dat[,i] = X[[i]]
}
#print(c("dat: ",dat, nrow(dat), ncol(dat)))
ind = j - MinSparse + 1
#trivial frobenius error
TrivialError = norm(invA - diag(SmallDimension)/SmallDimension,"F")^2 / normA
results$Trivial[ind] = results$Trivial[ind]+ TrivialError/(NumInstances*TrialsPerInstance)
#operator error
OpTrivialError = norm(invA - diag(SmallDimension)/SmallDimension,"I")^2
OpResults$Trivial[ind] = OpResults$Trivial[ind]+ OpTrivialError/(NumInstances*TrialsPerInstance)
#geodesic trivial
GeoTrivialError = GeodesicDistance(detinvA, diag(SmallDimension))
#GeoResults$Trivial[j] = GeoResults$Trivial[j] + GeoTrivialError/(NumInstances*TrialsPerInstance)
GeoResults$Trivial[ind] = GeoResults$Trivial[ind] + 1/(NumInstances*TrialsPerInstance)
#gemini
#set gemini penalties
GeminiRegFactor = 1*sqrt(log(SmallDimension)/BigDimension)
tic("geminiB")
out <- GeminiBmult(X, GeminiRegFactor, penalize.diagonal=FALSE)
toc()
GeminiEstimate = out$B.hat.inv
print(c("Gemini det",det(GeminiEstimate)))
#calculate frobenius error
GeminiError = norm(invA - (GeminiEstimate/tr(GeminiEstimate)),"F")^2 / normA
results$Gemini[ind] = results$Gemini[ind]+ GeminiError/(NumInstances*TrialsPerInstance)
#operator error
OpGeminiError = norm(invA - (GeminiEstimate/tr(GeminiEstimate)),"I")^2
OpResults$Gemini[ind] = OpResults$Gemini[ind]+ OpGeminiError/(NumInstances*TrialsPerInstance)
#calculate geodesic error
GeoGeminiError = GeodesicDistance(detinvA, DetNorm(GeminiEstimate))^2/GeoTrivialError^2
GeoResults$Gemini[ind] = GeoResults$Gemini[ind] + GeoGeminiError/(NumInstances*TrialsPerInstance)
######Sinkhorn
#regularized Sinkhorn
#set sinkhorn penalties
tic("sinkhorn")
SinkEstimate = sinkhorn(X,tol = .01)[[1]]
toc()
#print(c("Sinkhorn det",det(RegSinkEstimate)))
#calculate frobenius
SinkError = norm(invA - (SinkEstimate/tr(SinkEstimate)),"F")^2 / normA
results$Sink[ind] = results$Sink[ind]+ SinkError/(NumInstances*TrialsPerInstance)
#operator error
OpUnregSinkError = norm(invA - (SinkEstimate/tr(SinkEstimate)),"I")^2
OpResults$Sink[ind] = OpResults$Sink[ind]+ OpUnregSinkError/(NumInstances*TrialsPerInstance)
#geodesic distance
GeoUnregSinkError = GeodesicDistance(DetNorm(invA), DetNorm(SinkEstimate))^2/GeoTrivialError^2
GeoResults$Sink[ind] = GeoResults$Sink[ind] + GeoUnregSinkError/(NumInstances*TrialsPerInstance)
#regularized Sinkhorn
#set sinkhorn penalties
RegSinkFactor = 1
tic("regularized sinkhorn")
RegSinkEstimate = regsinkhorn(X,tol = .01, reg = RegSinkFactor)[[1]]
toc()
print(c("Sinkhorn det",det(RegSinkEstimate)))
#calculate frobenius
RegSinkError = norm(invA - (RegSinkEstimate/tr(RegSinkEstimate)),"F")^2 / normA
results$RegSink[ind] = results$RegSink[ind]+ RegSinkError/(NumInstances*TrialsPerInstance)
#operator error
OpSinkError = norm(invA - (RegSinkEstimate/tr(RegSinkEstimate)),"I")^2
OpResults$RegSink[ind] = OpResults$RegSink[ind]+ OpSinkError/(NumInstances*TrialsPerInstance)
#geodesic distance
GeoSinkError = GeodesicDistance(DetNorm(invA), DetNorm(RegSinkEstimate))^2/GeoTrivialError^2
GeoResults$RegSink[ind] = GeoResults$RegSink[ind] + GeoSinkError/(NumInstances*TrialsPerInstance)
#KGlasso
#print(c("MatReg, ", MatReg))
setVariable(matlab, dat = dat)
#evaluate(matlab, "SmallDimension, class(BigDimension),class(NumSamples)")
evaluate(matlab,"[C,D] = KGL_R(dat,SmallDimension,BigDimension,NumSamples,.4,.4,30,.01);")
KGlassoEstimate = getVariable(matlab,"C")$C
KGlassoError = norm(invA - (KGlassoEstimate/tr(KGlassoEstimate)),"F")^2 / normA
#print(c("Glasso Error: ",KGlassoError))
results$KGlasso[ind] = results$KGlasso[ind]+ KGlassoError/(NumInstances*TrialsPerInstance)
#operator error
OpKGlassoError = norm(invA - (KGlassoEstimate/tr(KGlassoEstimate)),"I")^2
OpResults$KGlasso[ind] = OpResults$KGlasso[ind]+ OpKGlassoError/(NumInstances*TrialsPerInstance)
#geodesic distance
GeoKGlassoError = GeodesicDistance(DetNorm(invA), DetNorm(KGlassoEstimate))^2/GeoTrivialError^2
GeoResults$KGlasso[ind] = GeoResults$KGlasso[ind] + GeoKGlassoError/(NumInstances*TrialsPerInstance)
}
}
}
output<- list(Results = results,OpResults = OpResults, GeoResults = GeoResults, Example=A[1:min(SmallDimension,10),1:min(SmallDimension,10)])
}
#doing the learning curves
res =SparsityCurve(20,20,1,4,10)
#this time let n to infinity. Question: what model? Sparse?
SparsityCurve <-function(SmallDimension,BigDimension,NumSamples, MinSparse,MaxSparse,NumInstances=2,TrialsPerInstance=2){
results = data.frame(Sparsity = c(MinSparse:MaxSparse),Gemini=0,RegSink = 0,Sink = 0, Trivial=0, KGlasso = 0)
#make copies for the other error metrics.
GeoResults = data.frame(results)
OpResults = data.frame(results)
setVariable(matlab, SmallDimension=SmallDimension, BigDimension=BigDimension,NumSamples=NumSamples)
for(j in MinSparse:MaxSparse){
for (l in 1:NumInstances){
#define sparse INVERSE covariance
invA = .5*diag(SmallDimension)
for (term in 1:SmallDimension*j/10){
#print(term)
x=sample(1:SmallDimension,2,replace=F)
invA[x[1],x[1]]=invA[x[1],x[1]]+1
invA[x[1],x[2]]=invA[x[1],x[2]]-1
invA[x[2],x[1]]=invA[x[2],x[1]]-1
invA[x[2],x[2]]=invA[x[2],x[2]]+1
}
A = solve(invA)
rootA = sqrtm(A)
invA = invA/tr(invA)
normA = norm(invA,"F")^2
detinvA = DetNorm(invA)
#print(c("detA",det(invA)))
#actually the INVERSE should be sparse
invB = .5*diag(BigDimension)
for (term in 1:BigDimension*j/10){
#print(term)
x=sample(1:BigDimension,2,replace=F)
invB[x[1],x[1]]=invB[x[1],x[1]]+1
invB[x[1],x[2]]=invB[x[1],x[2]]-1
invB[x[2],x[1]]=invB[x[2],x[1]]-1
invB[x[2],x[2]]=invB[x[2],x[2]]+1
}
B = solve(invB)
rootB = sqrtm(B)
invB = invB/tr(invB)
normB = norm(invB,"F")^2
detinvB = DetNorm(invB)
#for each covariance we will compute the estimate with fresh samples from the model a few times
for(k in 1:TrialsPerInstance){
#create the fresh samples
X = list(0*c(1:NumSamples))
dat = matrix(0, ncol = NumSamples, nrow = SmallDimension*BigDimension)
for(i in 1:NumSamples){
#create the data
X[[i]] = rootA%*%matrix(rnorm(SmallDimension*BigDimension,sd=1), nrow=SmallDimension, ncol=BigDimension)%*%rootB
dat[,i] = X[[i]]
}
#print(c("dat: ",dat, nrow(dat), ncol(dat)))
ind = j - MinSparse + 1
#trivial frobenius error
TrivialError = norm(invA - diag(SmallDimension)/SmallDimension,"F")^2 / normA
results$Trivial[ind] = results$Trivial[ind]+ TrivialError/(NumInstances*TrialsPerInstance)
#operator error
OpTrivialError = norm(invA - diag(SmallDimension)/SmallDimension,"I")^2
OpResults$Trivial[ind] = OpResults$Trivial[ind]+ OpTrivialError/(NumInstances*TrialsPerInstance)
#geodesic trivial
GeoTrivialError = GeodesicDistance(detinvA, diag(SmallDimension))
#GeoResults$Trivial[j] = GeoResults$Trivial[j] + GeoTrivialError/(NumInstances*TrialsPerInstance)
GeoResults$Trivial[ind] = GeoResults$Trivial[ind] + 1/(NumInstances*TrialsPerInstance)
#gemini
#set gemini penalties
GeminiRegFactor = 1*sqrt(log(SmallDimension)/BigDimension)
tic("geminiB")
out <- GeminiBmult(X, GeminiRegFactor, penalize.diagonal=FALSE)
toc()
GeminiEstimate = out$B.hat.inv
print(c("Gemini det",det(GeminiEstimate)))
#calculate frobenius error
GeminiError = norm(invA - (GeminiEstimate/tr(GeminiEstimate)),"F")^2 / normA
results$Gemini[ind] = results$Gemini[ind]+ GeminiError/(NumInstances*TrialsPerInstance)
#operator error
OpGeminiError = norm(invA - (GeminiEstimate/tr(GeminiEstimate)),"I")^2
OpResults$Gemini[ind] = OpResults$Gemini[ind]+ OpGeminiError/(NumInstances*TrialsPerInstance)
#calculate geodesic error
GeoGeminiError = GeodesicDistance(detinvA, DetNorm(GeminiEstimate))^2/GeoTrivialError^2
GeoResults$Gemini[ind] = GeoResults$Gemini[ind] + GeoGeminiError/(NumInstances*TrialsPerInstance)
######Sinkhorn
#regularized Sinkhorn
#set sinkhorn penalties
tic("sinkhorn")
SinkEstimate = sinkhorn(X,tol = .01)[[1]]
toc()
#print(c("Sinkhorn det",det(RegSinkEstimate)))
#calculate frobenius
SinkError = norm(invA - (SinkEstimate/tr(SinkEstimate)),"F")^2 / normA
results$Sink[ind] = results$Sink[ind]+ SinkError/(NumInstances*TrialsPerInstance)
#operator error
OpUnregSinkError = norm(invA - (SinkEstimate/tr(SinkEstimate)),"I")^2
OpResults$Sink[ind] = OpResults$Sink[ind]+ OpUnregSinkError/(NumInstances*TrialsPerInstance)
#geodesic distance
GeoUnregSinkError = GeodesicDistance(DetNorm(invA), DetNorm(SinkEstimate))^2/GeoTrivialError^2
GeoResults$Sink[ind] = GeoResults$Sink[ind] + GeoUnregSinkError/(NumInstances*TrialsPerInstance)
#regularized Sinkhorn
#set sinkhorn penalties
RegSinkFactor = 1
tic("regularized sinkhorn")
RegSinkEstimate = regsinkhorn(X,tol = .01, reg = RegSinkFactor)[[1]]
toc()
print(c("Sinkhorn det",det(RegSinkEstimate)))
#calculate frobenius
RegSinkError = norm(invA - (RegSinkEstimate/tr(RegSinkEstimate)),"F")^2 / normA
results$RegSink[ind] = results$RegSink[ind]+ RegSinkError/(NumInstances*TrialsPerInstance)
#operator error
OpSinkError = norm(invA - (RegSinkEstimate/tr(RegSinkEstimate)),"I")^2
OpResults$RegSink[ind] = OpResults$RegSink[ind]+ OpSinkError/(NumInstances*TrialsPerInstance)
#geodesic distance
GeoSinkError = GeodesicDistance(DetNorm(invA), DetNorm(RegSinkEstimate))^2/GeoTrivialError^2
GeoResults$RegSink[ind] = GeoResults$RegSink[ind] + GeoSinkError/(NumInstances*TrialsPerInstance)
#KGlasso
#print(c("MatReg, ", MatReg))
setVariable(matlab, dat = dat)
#evaluate(matlab, "SmallDimension, class(BigDimension),class(NumSamples)")
evaluate(matlab,"[C,D] = KGL_R(dat,SmallDimension,BigDimension,NumSamples,.4,.4,30,.01);")
KGlassoEstimate = getVariable(matlab,"C")$C
KGlassoError = norm(invA - (KGlassoEstimate/tr(KGlassoEstimate)),"F")^2 / normA
#print(c("Glasso Error: ",KGlassoError))
results$KGlasso[ind] = results$KGlasso[ind]+ KGlassoError/(NumInstances*TrialsPerInstance)
#operator error
OpKGlassoError = norm(invA - (KGlassoEstimate/tr(KGlassoEstimate)),"I")^2
OpResults$KGlasso[ind] = OpResults$KGlasso[ind]+ OpKGlassoError/(NumInstances*TrialsPerInstance)
#geodesic distance
GeoKGlassoError = GeodesicDistance(DetNorm(invA), DetNorm(KGlassoEstimate))^2/GeoTrivialError^2
GeoResults$KGlasso[ind] = GeoResults$KGlasso[ind] + GeoKGlassoError/(NumInstances*TrialsPerInstance)
}
}
}
output<- list(Results = results,OpResults = OpResults, GeoResults = GeoResults, Example=A[1:min(SmallDimension,10),1:min(SmallDimension,10)])
}
#doing the learning curves
res =SparsityCurve(20,20,1,4,10)
lp = SparseCurvePlot(res$Results)
SparseCurvePlot <- function(results){
mytheme <- theme(legend.text = element_text(family = "Helvetica", size = rel(1)),
#legend.position = "top",
axis.title = element_text(family = "Helvetica", size = rel(1)),
axis.text = element_text(family = "Helvetica", size = rel(1)),
axis.line = element_line(size = 1,colour = "black"),
axis.ticks = element_line(colour="black",size = rel(1)),
panel.grid.major = element_line(colour="grey90",size = rel(0.5)),
panel.grid.minor = element_blank(),
panel.background = element_rect(fill = "grey98"),
legend.key = element_rect(fill = "grey98"),
legend.title = element_text(family = "Helvetica", size = rel(1)),
plot.title = element_text(face = "bold", size = rel(1.25),family = "Helvetica"))
df = melt(results, id.vars = "Sparsity",variable.name = "Algorithm", value.name = "Error")
#df = melt(results, id.vars = "Regularizer",variable.name = "Algorithm")
lp <- ggplot(data=df, aes(x=Sparsity, y=Error, group=Algorithm, color=Algorithm)) + geom_line() + geom_point() + scale_x_log10(breaks = 10^(-10:10),labels = trans_format("log10", math_format(10^.x)))+ scale_y_log10(breaks = 10^(-10:10),labels = trans_format("log10", math_format(10^.x)))+ mytheme
return(lp)}
lp = SparseCurvePlot(res$Results)
lp
#doing the learning curves
res =SparsityCurve(20,20,1,4,20)
lp = SparseCurvePlot(res$Results)
lp
#doing the learning curves
res =SparsityCurve(20,20,1,20,40)
lp = SparseCurvePlot(res$Results)
lp
res$Example
#doing the learning curves
res =SparsityCurve(20,20,1,40,60)
lp = SparseCurvePlot(res$Results)
lp
#do the plots
#geodesic
lp=SparseCurvePlot(res$GeoResults)
lp = lp + ggtitle("Error in Geodesic distance") #cool way to title on the fly :)
pdf("25-50-sc-geo.pdf")
lp
dev.off()
lp
lp=SparseCurvePlot(res$OpResults)
lp = lp + ggtitle("Error in operator norm")
pdf("25-50-sc-op.pdf")
lp
dev.off()
lp
lp=SparseCurvePlot(res$Results)
lp = lp + ggtitle("Error in Frobenius norm")
pdf("25-50-sc-frob.pdf")
lp
dev.off()
lp
