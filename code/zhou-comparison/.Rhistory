#set gemini penalties
GeminiRegFactor = 1*sqrt(log(SmallDimension)/BigDimension)
tic("geminiB")
out <- GeminiBmult(X, GeminiRegFactor, penalize.diagonal=FALSE)
toc()
GeminiEstimate = out$B.hat.inv
print(c("Gemini det",det(GeminiEstimate)))
#calculate frobenius error
GeminiError = norm(invA - (GeminiEstimate/tr(GeminiEstimate)),"F")^2 / normA
results$Gemini[j] = results$Gemini[j]+ GeminiError/(NumInstances*TrialsPerInstance)
#operator error
OpGeminiError = norm(invA - (GeminiEstimate/tr(GeminiEstimate)),"I")^2
OpResults$Gemini[j] = OpResults$Gemini[j]+ OpGeminiError/(NumInstances*TrialsPerInstance)
#calculate geodesic error
GeoGeminiError = GeodesicDistance(detinvA, DetNorm(GeminiEstimate))^2/GeoTrivialError^2
GeoResults$Gemini[j] = GeoResults$Gemini[j] + GeoGeminiError/(NumInstances*TrialsPerInstance)
#regularized Sinkhorn
#set sinkhorn penalties
RegSinkFactor = 1
tic("regularized sinkhorn")
RegSinkEstimate = regsinkhorn(X,tol = .01, reg = RegSinkFactor)[[1]]
toc()
print(c("Sinkhorn det",det(RegSinkEstimate)))
#calculate frobenius
RegSinkError = norm(invA - (RegSinkEstimate/tr(RegSinkEstimate)),"F")^2 / normA
results$RegSink[j] = results$RegSink[j]+ RegSinkError/(NumInstances*TrialsPerInstance)
#operator error
OpSinkError = norm(invA - (RegSinkEstimate/tr(RegSinkEstimate)),"I")^2
OpResults$RegSink[j] = OpResults$RegSink[j]+ OpSinkError/(NumInstances*TrialsPerInstance)
#geodesic distance
GeoSinkError = GeodesicDistance(DetNorm(invA), DetNorm(RegSinkEstimate))^2/GeoTrivialError^2
GeoResults$RegSink[j] = GeoResults$RegSink[j] + GeoSinkError/(NumInstances*TrialsPerInstance)
#KGlasso
#print(c("MatReg, ", MatReg))
setVariable(matlab, dat = dat,j=j)
evaluate(matlab,"[C,D] = KGL_R(dat,SmallDimension,BigDimension,j,.4,.4,10,.01);")
KGlassoEstimate = getVariable(matlab,"C")$C
KGlassoError = norm(invA - (KGlassoEstimate/tr(KGlassoEstimate)),"F")^2 / normA
#print(c("Glasso Error: ",KGlassoError))
results$KGlasso[j] = results$KGlasso[j]+ KGlassoError/(NumInstances*TrialsPerInstance)
#operator error
OpKGlassoError = norm(invA - (KGlassoEstimate/tr(KGlassoEstimate)),"I")^2
OpResults$KGlasso[j] = OpResults$KGlasso[j]+ OpKGlassoError/(NumInstances*TrialsPerInstance)
#geodesic distance
GeoKGlassoError = GeodesicDistance(DetNorm(invA), DetNorm(KGlassoEstimate))^2/GeoTrivialError^2
GeoResults$KGlasso[j] = GeoResults$KGlasso[j] + GeoKGlassoError/(NumInstances*TrialsPerInstance)
}
}
}
output<- list(Results = results,OpResults = OpResults, GeoResults = GeoResults, Example=A[1:min(SmallDimension,10),1:min(SmallDimension,10)])
}
#doing the learning curves
res =LearningCurve(2,2,1,5)
#this time let n to infinity. Question: what model? Sparse?
LearningCurve <-function(SmallDimension,BigDimension,MinSamples,MaxSamples,NumInstances=2,TrialsPerInstance=2,spike = 10,RegMin = -5, RegMax =5, RegStride=1){
results = data.frame(SampleNumber = c(MinSamples:MaxSamples),Gemini=0,RegSink = 0,Trivial=0, KGlasso = 0)
#make copies for the other error metrics.
GeoResults = data.frame(results)
OpResults = data.frame(results)
setVariable(matlab, SmallDimension=SmallDimension, BigDimension=BigDimension)
for(j in MinSamples:MaxSamples){
for (l in 1:NumInstances){
#define sparse INVERSE covariance
invA = .5*diag(SmallDimension)
for (term in 1:SmallDimension*sparsity/10){
#print(term)
x=sample(1:SmallDimension,2,replace=F)
invA[x[1],x[1]]=invA[x[1],x[1]]+1
invA[x[1],x[2]]=invA[x[1],x[2]]-1
invA[x[2],x[1]]=invA[x[2],x[1]]-1
invA[x[2],x[2]]=invA[x[2],x[2]]+1
}
A = solve(invA)
rootA = sqrtm(A)
invA = invA/tr(invA)
normA = norm(invA,"F")^2
detinvA = DetNorm(invA)
#print(c("detA",det(invA)))
#actually the INVERSE should be sparse
invB = .5*diag(BigDimension)
for (term in 1:BigDimension*sparsity/10){
#print(term)
x=sample(1:BigDimension,2,replace=F)
invB[x[1],x[1]]=invB[x[1],x[1]]+1
invB[x[1],x[2]]=invB[x[1],x[2]]-1
invB[x[2],x[1]]=invB[x[2],x[1]]-1
invB[x[2],x[2]]=invB[x[2],x[2]]+1
}
B = solve(invB)
rootB = sqrtm(B)
invB = invB/tr(invB)
normB = norm(invB,"F")^2
detinvB = DetNorm(invB)
#for each covariance we will compute the estimate with fresh samples from the model a few times
for(k in 1:TrialsPerInstance){
#create the fresh samples
X = list(0*c(1:NumSamples))
dat = matrix(0, ncol = NumSamples, nrow = SmallDimension*BigDimension)
for(i in 1:NumSamples){
#create the data
X[[i]] = rootA%*%matrix(rnorm(SmallDimension*BigDimension,sd=1), nrow=SmallDimension, ncol=BigDimension)%*%rootB
dat[,i] = X[[i]]
}
#print(c("dat: ",dat, nrow(dat), ncol(dat)))
#trivial frobenius error
TrivialError = norm(invA - diag(SmallDimension)/SmallDimension,"F")^2 / normA
results$Trivial[j] = results$Trivial[j]+ TrivialError/(NumInstances*TrialsPerInstance)
#operator error
OpTrivialError = norm(invA - diag(SmallDimension)/SmallDimension,"I")^2
OpResults$Trivial[j] = OpResults$Trivial[j]+ OpTrivialError/(NumInstances*TrialsPerInstance)
#geodesic trivial
GeoTrivialError = GeodesicDistance(detinvA, diag(SmallDimension))
#GeoResults$Trivial[j] = GeoResults$Trivial[j] + GeoTrivialError/(NumInstances*TrialsPerInstance)
GeoResults$Trivial[j] = GeoResults$Trivial[j] + 1/(NumInstances*TrialsPerInstance)
#gemini
#set gemini penalties
GeminiRegFactor = 1*sqrt(log(SmallDimension)/BigDimension)
tic("geminiB")
out <- GeminiBmult(X, GeminiRegFactor, penalize.diagonal=FALSE)
toc()
GeminiEstimate = out$B.hat.inv
print(c("Gemini det",det(GeminiEstimate)))
#calculate frobenius error
GeminiError = norm(invA - (GeminiEstimate/tr(GeminiEstimate)),"F")^2 / normA
results$Gemini[j] = results$Gemini[j]+ GeminiError/(NumInstances*TrialsPerInstance)
#operator error
OpGeminiError = norm(invA - (GeminiEstimate/tr(GeminiEstimate)),"I")^2
OpResults$Gemini[j] = OpResults$Gemini[j]+ OpGeminiError/(NumInstances*TrialsPerInstance)
#calculate geodesic error
GeoGeminiError = GeodesicDistance(detinvA, DetNorm(GeminiEstimate))^2/GeoTrivialError^2
GeoResults$Gemini[j] = GeoResults$Gemini[j] + GeoGeminiError/(NumInstances*TrialsPerInstance)
#regularized Sinkhorn
#set sinkhorn penalties
RegSinkFactor = 1
tic("regularized sinkhorn")
RegSinkEstimate = regsinkhorn(X,tol = .01, reg = RegSinkFactor)[[1]]
toc()
print(c("Sinkhorn det",det(RegSinkEstimate)))
#calculate frobenius
RegSinkError = norm(invA - (RegSinkEstimate/tr(RegSinkEstimate)),"F")^2 / normA
results$RegSink[j] = results$RegSink[j]+ RegSinkError/(NumInstances*TrialsPerInstance)
#operator error
OpSinkError = norm(invA - (RegSinkEstimate/tr(RegSinkEstimate)),"I")^2
OpResults$RegSink[j] = OpResults$RegSink[j]+ OpSinkError/(NumInstances*TrialsPerInstance)
#geodesic distance
GeoSinkError = GeodesicDistance(DetNorm(invA), DetNorm(RegSinkEstimate))^2/GeoTrivialError^2
GeoResults$RegSink[j] = GeoResults$RegSink[j] + GeoSinkError/(NumInstances*TrialsPerInstance)
#KGlasso
#print(c("MatReg, ", MatReg))
setVariable(matlab, dat = dat,j=j)
evaluate(matlab,"[C,D] = KGL_R(dat,SmallDimension,BigDimension,j,.4,.4,10,.01);")
KGlassoEstimate = getVariable(matlab,"C")$C
KGlassoError = norm(invA - (KGlassoEstimate/tr(KGlassoEstimate)),"F")^2 / normA
#print(c("Glasso Error: ",KGlassoError))
results$KGlasso[j] = results$KGlasso[j]+ KGlassoError/(NumInstances*TrialsPerInstance)
#operator error
OpKGlassoError = norm(invA - (KGlassoEstimate/tr(KGlassoEstimate)),"I")^2
OpResults$KGlasso[j] = OpResults$KGlasso[j]+ OpKGlassoError/(NumInstances*TrialsPerInstance)
#geodesic distance
GeoKGlassoError = GeodesicDistance(DetNorm(invA), DetNorm(KGlassoEstimate))^2/GeoTrivialError^2
GeoResults$KGlasso[j] = GeoResults$KGlasso[j] + GeoKGlassoError/(NumInstances*TrialsPerInstance)
}
}
}
output<- list(Results = results,OpResults = OpResults, GeoResults = GeoResults, Example=A[1:min(SmallDimension,10),1:min(SmallDimension,10)])
}
#this time let n to infinity. Question: what model? Sparse?
LearningCurve <-function(SmallDimension,BigDimension,MinSamples,MaxSamples,NumInstances=2,TrialsPerInstance=2,spike = 10,RegMin = -5, RegMax =5, RegStride=1){
results = data.frame(SampleNumber = c(MinSamples:MaxSamples),Gemini=0,RegSink = 0,Trivial=0, KGlasso = 0)
#make copies for the other error metrics.
GeoResults = data.frame(results)
OpResults = data.frame(results)
setVariable(matlab, SmallDimension=SmallDimension, BigDimension=BigDimension)
for(j in MinSamples:MaxSamples){
setVariable(matlab, j=j)
for (l in 1:NumInstances){
#define sparse INVERSE covariance
invA = .5*diag(SmallDimension)
for (term in 1:SmallDimension*sparsity/10){
#print(term)
x=sample(1:SmallDimension,2,replace=F)
invA[x[1],x[1]]=invA[x[1],x[1]]+1
invA[x[1],x[2]]=invA[x[1],x[2]]-1
invA[x[2],x[1]]=invA[x[2],x[1]]-1
invA[x[2],x[2]]=invA[x[2],x[2]]+1
}
A = solve(invA)
rootA = sqrtm(A)
invA = invA/tr(invA)
normA = norm(invA,"F")^2
detinvA = DetNorm(invA)
#print(c("detA",det(invA)))
#actually the INVERSE should be sparse
invB = .5*diag(BigDimension)
for (term in 1:BigDimension*sparsity/10){
#print(term)
x=sample(1:BigDimension,2,replace=F)
invB[x[1],x[1]]=invB[x[1],x[1]]+1
invB[x[1],x[2]]=invB[x[1],x[2]]-1
invB[x[2],x[1]]=invB[x[2],x[1]]-1
invB[x[2],x[2]]=invB[x[2],x[2]]+1
}
B = solve(invB)
rootB = sqrtm(B)
invB = invB/tr(invB)
normB = norm(invB,"F")^2
detinvB = DetNorm(invB)
#for each covariance we will compute the estimate with fresh samples from the model a few times
for(k in 1:TrialsPerInstance){
#create the fresh samples
X = list(0*c(1:NumSamples))
dat = matrix(0, ncol = NumSamples, nrow = SmallDimension*BigDimension)
for(i in 1:NumSamples){
#create the data
X[[i]] = rootA%*%matrix(rnorm(SmallDimension*BigDimension,sd=1), nrow=SmallDimension, ncol=BigDimension)%*%rootB
dat[,i] = X[[i]]
}
#print(c("dat: ",dat, nrow(dat), ncol(dat)))
#trivial frobenius error
TrivialError = norm(invA - diag(SmallDimension)/SmallDimension,"F")^2 / normA
results$Trivial[j] = results$Trivial[j]+ TrivialError/(NumInstances*TrialsPerInstance)
#operator error
OpTrivialError = norm(invA - diag(SmallDimension)/SmallDimension,"I")^2
OpResults$Trivial[j] = OpResults$Trivial[j]+ OpTrivialError/(NumInstances*TrialsPerInstance)
#geodesic trivial
GeoTrivialError = GeodesicDistance(detinvA, diag(SmallDimension))
#GeoResults$Trivial[j] = GeoResults$Trivial[j] + GeoTrivialError/(NumInstances*TrialsPerInstance)
GeoResults$Trivial[j] = GeoResults$Trivial[j] + 1/(NumInstances*TrialsPerInstance)
#gemini
#set gemini penalties
GeminiRegFactor = 1*sqrt(log(SmallDimension)/BigDimension)
tic("geminiB")
out <- GeminiBmult(X, GeminiRegFactor, penalize.diagonal=FALSE)
toc()
GeminiEstimate = out$B.hat.inv
print(c("Gemini det",det(GeminiEstimate)))
#calculate frobenius error
GeminiError = norm(invA - (GeminiEstimate/tr(GeminiEstimate)),"F")^2 / normA
results$Gemini[j] = results$Gemini[j]+ GeminiError/(NumInstances*TrialsPerInstance)
#operator error
OpGeminiError = norm(invA - (GeminiEstimate/tr(GeminiEstimate)),"I")^2
OpResults$Gemini[j] = OpResults$Gemini[j]+ OpGeminiError/(NumInstances*TrialsPerInstance)
#calculate geodesic error
GeoGeminiError = GeodesicDistance(detinvA, DetNorm(GeminiEstimate))^2/GeoTrivialError^2
GeoResults$Gemini[j] = GeoResults$Gemini[j] + GeoGeminiError/(NumInstances*TrialsPerInstance)
#regularized Sinkhorn
#set sinkhorn penalties
RegSinkFactor = 1
tic("regularized sinkhorn")
RegSinkEstimate = regsinkhorn(X,tol = .01, reg = RegSinkFactor)[[1]]
toc()
print(c("Sinkhorn det",det(RegSinkEstimate)))
#calculate frobenius
RegSinkError = norm(invA - (RegSinkEstimate/tr(RegSinkEstimate)),"F")^2 / normA
results$RegSink[j] = results$RegSink[j]+ RegSinkError/(NumInstances*TrialsPerInstance)
#operator error
OpSinkError = norm(invA - (RegSinkEstimate/tr(RegSinkEstimate)),"I")^2
OpResults$RegSink[j] = OpResults$RegSink[j]+ OpSinkError/(NumInstances*TrialsPerInstance)
#geodesic distance
GeoSinkError = GeodesicDistance(DetNorm(invA), DetNorm(RegSinkEstimate))^2/GeoTrivialError^2
GeoResults$RegSink[j] = GeoResults$RegSink[j] + GeoSinkError/(NumInstances*TrialsPerInstance)
#KGlasso
#print(c("MatReg, ", MatReg))
setVariable(matlab, dat = dat)
evaluate(matlab,"[C,D] = KGL_R(dat,SmallDimension,BigDimension,j,.4,.4,10,.01);")
KGlassoEstimate = getVariable(matlab,"C")$C
KGlassoError = norm(invA - (KGlassoEstimate/tr(KGlassoEstimate)),"F")^2 / normA
#print(c("Glasso Error: ",KGlassoError))
results$KGlasso[j] = results$KGlasso[j]+ KGlassoError/(NumInstances*TrialsPerInstance)
#operator error
OpKGlassoError = norm(invA - (KGlassoEstimate/tr(KGlassoEstimate)),"I")^2
OpResults$KGlasso[j] = OpResults$KGlasso[j]+ OpKGlassoError/(NumInstances*TrialsPerInstance)
#geodesic distance
GeoKGlassoError = GeodesicDistance(DetNorm(invA), DetNorm(KGlassoEstimate))^2/GeoTrivialError^2
GeoResults$KGlasso[j] = GeoResults$KGlasso[j] + GeoKGlassoError/(NumInstances*TrialsPerInstance)
}
}
}
output<- list(Results = results,OpResults = OpResults, GeoResults = GeoResults, Example=A[1:min(SmallDimension,10),1:min(SmallDimension,10)])
}
#this time let n to infinity. Question: what model? Sparse?
LearningCurve <-function(SmallDimension,BigDimension,MinSamples,MaxSamples,NumInstances=2,TrialsPerInstance=2,spike = 10,RegMin = -5, RegMax =5, RegStride=1){
results = data.frame(SampleNumber = c(MinSamples:MaxSamples),Gemini=0,RegSink = 0,Trivial=0, KGlasso = 0)
#make copies for the other error metrics.
GeoResults = data.frame(results)
OpResults = data.frame(results)
setVariable(matlab, SmallDimension=SmallDimension, BigDimension=BigDimension)
for(j in MinSamples:MaxSamples){
setVariable(matlab, j=j)
for (l in 1:NumInstances){
#define sparse INVERSE covariance
invA = .5*diag(SmallDimension)
for (term in 1:SmallDimension*sparsity/10){
#print(term)
x=sample(1:SmallDimension,2,replace=F)
invA[x[1],x[1]]=invA[x[1],x[1]]+1
invA[x[1],x[2]]=invA[x[1],x[2]]-1
invA[x[2],x[1]]=invA[x[2],x[1]]-1
invA[x[2],x[2]]=invA[x[2],x[2]]+1
}
A = solve(invA)
rootA = sqrtm(A)
invA = invA/tr(invA)
normA = norm(invA,"F")^2
detinvA = DetNorm(invA)
#print(c("detA",det(invA)))
#actually the INVERSE should be sparse
invB = .5*diag(BigDimension)
for (term in 1:BigDimension*sparsity/10){
#print(term)
x=sample(1:BigDimension,2,replace=F)
invB[x[1],x[1]]=invB[x[1],x[1]]+1
invB[x[1],x[2]]=invB[x[1],x[2]]-1
invB[x[2],x[1]]=invB[x[2],x[1]]-1
invB[x[2],x[2]]=invB[x[2],x[2]]+1
}
B = solve(invB)
rootB = sqrtm(B)
invB = invB/tr(invB)
normB = norm(invB,"F")^2
detinvB = DetNorm(invB)
#for each covariance we will compute the estimate with fresh samples from the model a few times
for(k in 1:TrialsPerInstance){
#create the fresh samples
X = list(0*c(1:NumSamples))
dat = matrix(0, ncol = NumSamples, nrow = SmallDimension*BigDimension)
for(i in 1:NumSamples){
#create the data
X[[i]] = rootA%*%matrix(rnorm(SmallDimension*BigDimension,sd=1), nrow=SmallDimension, ncol=BigDimension)%*%rootB
dat[,i] = X[[i]]
}
#print(c("dat: ",dat, nrow(dat), ncol(dat)))
#trivial frobenius error
TrivialError = norm(invA - diag(SmallDimension)/SmallDimension,"F")^2 / normA
results$Trivial[j] = results$Trivial[j]+ TrivialError/(NumInstances*TrialsPerInstance)
#operator error
OpTrivialError = norm(invA - diag(SmallDimension)/SmallDimension,"I")^2
OpResults$Trivial[j] = OpResults$Trivial[j]+ OpTrivialError/(NumInstances*TrialsPerInstance)
#geodesic trivial
GeoTrivialError = GeodesicDistance(detinvA, diag(SmallDimension))
#GeoResults$Trivial[j] = GeoResults$Trivial[j] + GeoTrivialError/(NumInstances*TrialsPerInstance)
GeoResults$Trivial[j] = GeoResults$Trivial[j] + 1/(NumInstances*TrialsPerInstance)
#gemini
#set gemini penalties
GeminiRegFactor = 1*sqrt(log(SmallDimension)/BigDimension)
tic("geminiB")
out <- GeminiBmult(X, GeminiRegFactor, penalize.diagonal=FALSE)
toc()
GeminiEstimate = out$B.hat.inv
print(c("Gemini det",det(GeminiEstimate)))
#calculate frobenius error
GeminiError = norm(invA - (GeminiEstimate/tr(GeminiEstimate)),"F")^2 / normA
results$Gemini[j] = results$Gemini[j]+ GeminiError/(NumInstances*TrialsPerInstance)
#operator error
OpGeminiError = norm(invA - (GeminiEstimate/tr(GeminiEstimate)),"I")^2
OpResults$Gemini[j] = OpResults$Gemini[j]+ OpGeminiError/(NumInstances*TrialsPerInstance)
#calculate geodesic error
GeoGeminiError = GeodesicDistance(detinvA, DetNorm(GeminiEstimate))^2/GeoTrivialError^2
GeoResults$Gemini[j] = GeoResults$Gemini[j] + GeoGeminiError/(NumInstances*TrialsPerInstance)
#regularized Sinkhorn
#set sinkhorn penalties
RegSinkFactor = 1
tic("regularized sinkhorn")
RegSinkEstimate = regsinkhorn(X,tol = .01, reg = RegSinkFactor)[[1]]
toc()
print(c("Sinkhorn det",det(RegSinkEstimate)))
#calculate frobenius
RegSinkError = norm(invA - (RegSinkEstimate/tr(RegSinkEstimate)),"F")^2 / normA
results$RegSink[j] = results$RegSink[j]+ RegSinkError/(NumInstances*TrialsPerInstance)
#operator error
OpSinkError = norm(invA - (RegSinkEstimate/tr(RegSinkEstimate)),"I")^2
OpResults$RegSink[j] = OpResults$RegSink[j]+ OpSinkError/(NumInstances*TrialsPerInstance)
#geodesic distance
GeoSinkError = GeodesicDistance(DetNorm(invA), DetNorm(RegSinkEstimate))^2/GeoTrivialError^2
GeoResults$RegSink[j] = GeoResults$RegSink[j] + GeoSinkError/(NumInstances*TrialsPerInstance)
#KGlasso
#print(c("MatReg, ", MatReg))
setVariable(matlab, dat = dat)
evaluate(matlab,"[C,D] = KGL_R(dat,SmallDimension,BigDimension,j,.4,.4,10,.01);")
KGlassoEstimate = getVariable(matlab,"C")$C
KGlassoError = norm(invA - (KGlassoEstimate/tr(KGlassoEstimate)),"F")^2 / normA
#print(c("Glasso Error: ",KGlassoError))
results$KGlasso[j] = results$KGlasso[j]+ KGlassoError/(NumInstances*TrialsPerInstance)
#operator error
OpKGlassoError = norm(invA - (KGlassoEstimate/tr(KGlassoEstimate)),"I")^2
OpResults$KGlasso[j] = OpResults$KGlasso[j]+ OpKGlassoError/(NumInstances*TrialsPerInstance)
#geodesic distance
GeoKGlassoError = GeodesicDistance(DetNorm(invA), DetNorm(KGlassoEstimate))^2/GeoTrivialError^2
GeoResults$KGlasso[j] = GeoResults$KGlasso[j] + GeoKGlassoError/(NumInstances*TrialsPerInstance)
}
}
}
output<- list(Results = results,OpResults = OpResults, GeoResults = GeoResults, Example=A[1:min(SmallDimension,10),1:min(SmallDimension,10)])
}
#doing the learning curves
res =LearningCurve(2,2,1,5)
#this time let n to infinity. Question: what model? Sparse?
LearningCurve <-function(SmallDimension,BigDimension,MinSamples,MaxSamples,NumInstances=2,TrialsPerInstance=2,sparsity = 10,RegMin = -5, RegMax =5, RegStride=1){
results = data.frame(SampleNumber = c(MinSamples:MaxSamples),Gemini=0,RegSink = 0,Trivial=0, KGlasso = 0)
#make copies for the other error metrics.
GeoResults = data.frame(results)
OpResults = data.frame(results)
setVariable(matlab, SmallDimension=SmallDimension, BigDimension=BigDimension)
for(j in MinSamples:MaxSamples){
setVariable(matlab, j=j)
for (l in 1:NumInstances){
#define sparse INVERSE covariance
invA = .5*diag(SmallDimension)
for (term in 1:SmallDimension*sparsity/10){
#print(term)
x=sample(1:SmallDimension,2,replace=F)
invA[x[1],x[1]]=invA[x[1],x[1]]+1
invA[x[1],x[2]]=invA[x[1],x[2]]-1
invA[x[2],x[1]]=invA[x[2],x[1]]-1
invA[x[2],x[2]]=invA[x[2],x[2]]+1
}
A = solve(invA)
rootA = sqrtm(A)
invA = invA/tr(invA)
normA = norm(invA,"F")^2
detinvA = DetNorm(invA)
#print(c("detA",det(invA)))
#actually the INVERSE should be sparse
invB = .5*diag(BigDimension)
for (term in 1:BigDimension*sparsity/10){
#print(term)
x=sample(1:BigDimension,2,replace=F)
invB[x[1],x[1]]=invB[x[1],x[1]]+1
invB[x[1],x[2]]=invB[x[1],x[2]]-1
invB[x[2],x[1]]=invB[x[2],x[1]]-1
invB[x[2],x[2]]=invB[x[2],x[2]]+1
}
B = solve(invB)
rootB = sqrtm(B)
invB = invB/tr(invB)
normB = norm(invB,"F")^2
detinvB = DetNorm(invB)
#for each covariance we will compute the estimate with fresh samples from the model a few times
for(k in 1:TrialsPerInstance){
#create the fresh samples
X = list(0*c(1:NumSamples))
dat = matrix(0, ncol = NumSamples, nrow = SmallDimension*BigDimension)
for(i in 1:NumSamples){
#create the data
X[[i]] = rootA%*%matrix(rnorm(SmallDimension*BigDimension,sd=1), nrow=SmallDimension, ncol=BigDimension)%*%rootB
dat[,i] = X[[i]]
}
#print(c("dat: ",dat, nrow(dat), ncol(dat)))
#trivial frobenius error
TrivialError = norm(invA - diag(SmallDimension)/SmallDimension,"F")^2 / normA
results$Trivial[j] = results$Trivial[j]+ TrivialError/(NumInstances*TrialsPerInstance)
#operator error
OpTrivialError = norm(invA - diag(SmallDimension)/SmallDimension,"I")^2
OpResults$Trivial[j] = OpResults$Trivial[j]+ OpTrivialError/(NumInstances*TrialsPerInstance)
#geodesic trivial
GeoTrivialError = GeodesicDistance(detinvA, diag(SmallDimension))
#GeoResults$Trivial[j] = GeoResults$Trivial[j] + GeoTrivialError/(NumInstances*TrialsPerInstance)
GeoResults$Trivial[j] = GeoResults$Trivial[j] + 1/(NumInstances*TrialsPerInstance)
#gemini
#set gemini penalties
GeminiRegFactor = 1*sqrt(log(SmallDimension)/BigDimension)
tic("geminiB")
out <- GeminiBmult(X, GeminiRegFactor, penalize.diagonal=FALSE)
toc()
GeminiEstimate = out$B.hat.inv
print(c("Gemini det",det(GeminiEstimate)))
#calculate frobenius error
GeminiError = norm(invA - (GeminiEstimate/tr(GeminiEstimate)),"F")^2 / normA
results$Gemini[j] = results$Gemini[j]+ GeminiError/(NumInstances*TrialsPerInstance)
#operator error
OpGeminiError = norm(invA - (GeminiEstimate/tr(GeminiEstimate)),"I")^2
OpResults$Gemini[j] = OpResults$Gemini[j]+ OpGeminiError/(NumInstances*TrialsPerInstance)
#calculate geodesic error
GeoGeminiError = GeodesicDistance(detinvA, DetNorm(GeminiEstimate))^2/GeoTrivialError^2
GeoResults$Gemini[j] = GeoResults$Gemini[j] + GeoGeminiError/(NumInstances*TrialsPerInstance)
#regularized Sinkhorn
#set sinkhorn penalties
RegSinkFactor = 1
tic("regularized sinkhorn")
RegSinkEstimate = regsinkhorn(X,tol = .01, reg = RegSinkFactor)[[1]]
toc()
print(c("Sinkhorn det",det(RegSinkEstimate)))
#calculate frobenius
RegSinkError = norm(invA - (RegSinkEstimate/tr(RegSinkEstimate)),"F")^2 / normA
results$RegSink[j] = results$RegSink[j]+ RegSinkError/(NumInstances*TrialsPerInstance)
#operator error
OpSinkError = norm(invA - (RegSinkEstimate/tr(RegSinkEstimate)),"I")^2
OpResults$RegSink[j] = OpResults$RegSink[j]+ OpSinkError/(NumInstances*TrialsPerInstance)
#geodesic distance
GeoSinkError = GeodesicDistance(DetNorm(invA), DetNorm(RegSinkEstimate))^2/GeoTrivialError^2
GeoResults$RegSink[j] = GeoResults$RegSink[j] + GeoSinkError/(NumInstances*TrialsPerInstance)
#KGlasso
#print(c("MatReg, ", MatReg))
setVariable(matlab, dat = dat)
evaluate(matlab,"[C,D] = KGL_R(dat,SmallDimension,BigDimension,j,.4,.4,10,.01);")
KGlassoEstimate = getVariable(matlab,"C")$C
KGlassoError = norm(invA - (KGlassoEstimate/tr(KGlassoEstimate)),"F")^2 / normA
#print(c("Glasso Error: ",KGlassoError))
results$KGlasso[j] = results$KGlasso[j]+ KGlassoError/(NumInstances*TrialsPerInstance)
#operator error
OpKGlassoError = norm(invA - (KGlassoEstimate/tr(KGlassoEstimate)),"I")^2
OpResults$KGlasso[j] = OpResults$KGlasso[j]+ OpKGlassoError/(NumInstances*TrialsPerInstance)
#geodesic distance
GeoKGlassoError = GeodesicDistance(DetNorm(invA), DetNorm(KGlassoEstimate))^2/GeoTrivialError^2
GeoResults$KGlasso[j] = GeoResults$KGlasso[j] + GeoKGlassoError/(NumInstances*TrialsPerInstance)
}
}
}
output<- list(Results = results,OpResults = OpResults, GeoResults = GeoResults, Example=A[1:min(SmallDimension,10),1:min(SmallDimension,10)])
}
#doing the learning curves
res =LearningCurve(2,2,1,5)
